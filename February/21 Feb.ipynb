{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4f8b08-b2f9-4e75-977f-79cd7091ffd4",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15ea75-551b-45fc-870d-8115d22c14dd",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "\n",
    "Web scraping, also known as web data extraction, is the process of extracting structured data from websites. This involves automated software tools that are designed to crawl through web pages and collect information in a structured format.\n",
    "\n",
    "Web scraping can be done manually, but it's a time-consuming process that's prone to errors. Automated web scraping tools, on the other hand, can quickly and efficiently extract data from multiple web pages.\n",
    "\n",
    "\n",
    "It is use for several purpose: -\n",
    "\n",
    "Data Collection,\n",
    "Market Research,\n",
    "Lead Generation,\n",
    "Sentiment Analysis,\n",
    "Content Creation\n",
    "\n",
    "three areas where web scraping is commonly used to extract data: -\n",
    "\n",
    "E-commerce, \n",
    "Social Media, \n",
    "Market Research\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6505086-2d4e-481a-b3e4-472752a8cb9e",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    "\n",
    "Manual Copy and Paste: This is the most basic method of web scraping, where the user manually copies and pastes data from a website into a spreadsheet or database.\n",
    "\n",
    "Regular Expressions: Regular expressions (regex) can be used to extract specific patterns of data from HTML or XML files.\n",
    "\n",
    "HTML Parsing: HTML parsing involves using a parser to extract data from HTML files. This method is particularly useful for scraping structured data from websites.\n",
    "\n",
    "Web Scraping Libraries: There are several web scraping libraries available, including Beautiful Soup, Scrapy, and Requests. These libraries automate the process of web scraping and provide a range of tools for extracting and manipulating data.\n",
    "\n",
    "Headless Browsers: Headless browsers like Selenium can be used to simulate human interaction with a website, enabling web scraping of dynamic and interactive content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df70fa8d-7f5e-4587-8865-5ebd6f242e83",
   "metadata": {},
   "source": [
    "### Answer 3\n",
    "\n",
    "Beautiful Soup is a Python library used for web scraping purposes. It allows developers to extract data from HTML and XML files by providing a simple interface for parsing and navigating a web page's HTML structure.\n",
    "\n",
    "Beautiful Soup is widely used for web scraping because it is easy to learn and use, even for those who do not have extensive programming experience. It offers a range of tools for navigating, searching, and modifying HTML and XML files, making it a versatile tool for extracting data from web pages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b6482-4b6f-47e6-83cb-6b597cc7d5d0",
   "metadata": {},
   "source": [
    "### Answer 4\n",
    "\n",
    "Flask is a lightweight web framework that is commonly used for building web applications and APIs in Python. Flask is used in web scraping projects as a means of building a web application that can present the scraped data in a user-friendly way. Flask makes it easy to build a simple web interface for displaying the results of a web scraping project, allowing users to interact with the data in a more intuitive way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f0043-c0e8-41bc-ac45-835ec0d66146",
   "metadata": {},
   "source": [
    "### Answer 5\n",
    "\n",
    "Amazon EC2: EC2 is a virtual server that provides scalable computing resources. In a web scraping project, EC2 can be used to host web scraping scripts and run them in a scalable and reliable environment.\n",
    "\n",
    "Amazon S3: S3 is a cloud-based storage service that allows users to store and retrieve large amounts of data. In a web scraping project, S3 can be used to store scraped data, making it easily accessible for analysis and processing.\n",
    "\n",
    "AWS Lambda: Lambda is a serverless computing service that allows developers to run code without provisioning or managing servers. In a web scraping project, Lambda can be used to run scraping scripts and perform other processing tasks in a serverless environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cca2c1-6a18-4a3a-a3ce-004d15990041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
